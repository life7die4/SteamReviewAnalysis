{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "from konlpy.tag import Okt\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# 워드클라우드 폰트 경로 설정 (한글 지원용)\n",
    "FONT_PATH = \"C:/Windows/Fonts/malgun.ttf\"  # 윈도우 기준\n",
    "\n",
    "# 1. 리뷰 가져오기\n",
    "def fetch_steam_reviews(appid, language='all', count=100):\n",
    "    url = f'https://store.steampowered.com/appreviews/{appid}?json=1'\n",
    "    params = {\n",
    "        'filter': 'all',\n",
    "        'language': language,\n",
    "        'review_type': 'all',\n",
    "        'num_per_page': count\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return None\n",
    "\n",
    "# 2. 리뷰 CSV 저장\n",
    "def save_reviews_to_csv(appid):\n",
    "    languages = {'korean': 100, 'english': 100}\n",
    "    all_reviews = []\n",
    "\n",
    "    for lang, count in languages.items():\n",
    "        data = fetch_steam_reviews(appid, language=lang, count=count)\n",
    "        if data and 'reviews' in data:\n",
    "            for review in data['reviews']:\n",
    "                all_reviews.append({\n",
    "                    'language' : lang,\n",
    "                    'review_text' : review['review'],\n",
    "                    'helpful' : review['votes_up']\n",
    "                })\n",
    "                \n",
    "    filename = f\"../Output/steam_reviews_{appid}.csv\"    \n",
    "    df = pd.DataFrame(all_reviews)\n",
    "    df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Saved {len(df)} reviews to {filename}\")\n",
    "    return filename\n",
    "\n",
    "# 3. load_stopwords() 함수\n",
    "def load_stopwords(filepath):\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"[경고] 불용어 파일이 존재하지 않습니다: {filepath}\")\n",
    "        return set()\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        stopwords = set([line.strip() for line in f if line.strip()])\n",
    "    return stopwords\n",
    "\n",
    "\n",
    "# 3. 키워드 추출 함수 (갯수 조절 가능)\n",
    "def extract_keywords(text, is_korean=False, custom_stopwords=None, top_n=20, extra_stopwords=None):\n",
    "    if is_korean:\n",
    "        okt = Okt()\n",
    "        words = okt.nouns(text)\n",
    "\n",
    "        if custom_stopwords is None:\n",
    "            custom_stopwords = load_stopwords(\"../Data/stopwords-ko.txt\")\n",
    "\n",
    "        if extra_stopwords:\n",
    "            custom_stopwords.update(extra_stopwords)\n",
    "\n",
    "        words = [word for word in words if word not in custom_stopwords]\n",
    "\n",
    "    else:\n",
    "        tokenizer = TreebankWordTokenizer()\n",
    "        words = tokenizer.tokenize(text)\n",
    "        words = [word.lower() for word in words if word.isalnum()]\n",
    "\n",
    "        if custom_stopwords is None:\n",
    "            custom_stopwords = load_stopwords(\"../Data/stopwords-en.txt\")\n",
    "\n",
    "        if extra_stopwords:\n",
    "            custom_stopwords.update(extra_stopwords)\n",
    "\n",
    "        words = [word for word in words if word not in custom_stopwords]\n",
    "\n",
    "    return Counter(words).most_common(top_n)\n",
    "\n",
    "\n",
    "\n",
    "# 4. 리뷰에서 언어별 키워드 추출\n",
    "def process_reviews_for_keywords(csv_file, top_n=20,\n",
    "                                  custom_stopwords=None,\n",
    "                                  extra_korean_stopwords=None,\n",
    "                                  extra_english_stopwords=None):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    keyword_results = []\n",
    "\n",
    "    for lang in ['korean', 'english']:\n",
    "        is_korean = (lang == 'korean')\n",
    "        texts = ' '.join(df[df['language'] == lang]['review_text'].dropna())\n",
    "\n",
    "        # extra_stopwords는 언어별로 다르게 전달\n",
    "        extra = extra_korean_stopwords if is_korean else extra_english_stopwords\n",
    "\n",
    "        keywords = extract_keywords(\n",
    "            texts,\n",
    "            is_korean=is_korean,\n",
    "            custom_stopwords=custom_stopwords,\n",
    "            top_n=top_n,\n",
    "            extra_stopwords=extra\n",
    "        )\n",
    "\n",
    "        keyword_results.append({\n",
    "            'language': lang,\n",
    "            'keywords': keywords\n",
    "        })\n",
    "\n",
    "    return keyword_results\n",
    "\n",
    "\n",
    "# 5. 워드클라우드 생성 및 저장\n",
    "def generate_wordcloud(keywords, language):\n",
    "    word_dict = dict(keywords)\n",
    "    wc = WordCloud(\n",
    "        font_path=FONT_PATH,\n",
    "        background_color=None, # 'white'\n",
    "        colormap='Set2',\n",
    "        mode='RGBA',\n",
    "        width=800,\n",
    "        height=400\n",
    "    ).generate_from_frequencies(word_dict)\n",
    "\n",
    "    csv_output_path = f\"../Output/keyword_freq_{language}.csv\"\n",
    "    pd.DataFrame(keywords, columns=['word', 'frequency']).to_csv(csv_output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"{language} 키워드 빈도 CSV 저장 완료 → {csv_output_path}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"{language.capitalize()} 리뷰에 대한 워드 클라우드\")\n",
    "    \n",
    "    output_path = f\"../Output/wordcloud_{language}.png\"\n",
    "    wc.to_file(output_path)\n",
    "    print(f\"{language} 워드클라우드 저장 완료 → {output_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# 6. 전체 흐름 실행 함수\n",
    "def run_analysis(appid, top_n=20, extra_korean_stopwords=None, extra_english_stopwords=None):\n",
    "    csv_path = save_reviews_to_csv(appid)\n",
    "    results = process_reviews_for_keywords(\n",
    "        csv_file=csv_path,\n",
    "        top_n=top_n,\n",
    "        extra_korean_stopwords=extra_korean_stopwords,\n",
    "        extra_english_stopwords=extra_english_stopwords\n",
    "    )\n",
    "\n",
    "    for result in results:\n",
    "        generate_wordcloud(result['keywords'], result['language'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 200 reviews to ../Output/steam_reviews_2456740.csv\n",
      "korean 키워드 빈도 CSV 저장 완료 → ../Output/keyword_freq_korean.csv\n",
      "korean 워드클라우드 저장 완료 → ../Output/wordcloud_korean.png\n",
      "english 키워드 빈도 CSV 저장 완료 → ../Output/keyword_freq_english.csv\n",
      "english 워드클라우드 저장 완료 → ../Output/wordcloud_english.png\n"
     ]
    }
   ],
   "source": [
    "my_korean_stopwords = {'게임', '진짜', '완전'}\n",
    "my_english_stopwords = {'game', 'really', 'lol'}\n",
    "\n",
    "run_analysis(appid=2456740, \n",
    "             top_n=1000,\n",
    "             extra_korean_stopwords=my_korean_stopwords,\n",
    "             extra_english_stopwords=my_english_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
